# API Reference

[← Back to README](../README.md) | [Best Practices →](./BEST_PRACTICES.md)

> **Complete API documentation**: Parameters, return types, and code examples for all EdgeAI APIs.

---

## Chat API

### `EdgeAI.chat(request: ChatRequest): Flow<ChatResponse>`

**Parameters:**
```kotlin
data class ChatRequest(
    /**
     * Array of chat messages. Each message must include a role and content.
     */
    val messages: List<ChatMessage>,
    
    /**
     * The model ID to use for generating responses. If null, the engine will use the configured default.
     */
    val model: String? = null,
    
    /**
     * Audio output parameters. Required when requesting audio output.
     */
    val audio: AudioParams? = null,
    
    /**
     * Range: -2.0 ~ 2.0. Positive values penalize tokens that appear frequently.
     */
    val frequencyPenalty: Float? = 0f,
    
    /**
     * Adjusts the probability of specific tokens. Format: token ID mapped to bias value (-100~100).
     */
    val logitBias: Map<String, Float>? = null,
    
    /**
     * Whether to return log probabilities of output tokens.
     */
    val logprobs: Boolean? = false,
    
    /**
     * Limits the maximum number of tokens generated by the model.
     */
    val maxCompletionTokens: Int? = null,
    
    /**
     * Up to 16 key-value pairs for custom structured information.
     */
    val metadata: Map<String, String>? = null,
    
    /**
     * Specifies the desired output modalities. Default is ["text"].
     */
    val modalities: List<String>? = listOf("text"),
    
    /**
     * Number of response options to generate for each input message.
     */
    val n: Int? = 1,
    
    /**
     * Whether to enable parallel tool (function) calls.
     */
    val parallelToolCalls: Boolean? = true,
    
    /**
     * Prediction output settings for faster responses.
     */
    val prediction: PredictionParams? = null,
    
    /**
     * Range: -2.0 ~ 2.0. Positive values encourage new topics.
     */
    val presencePenalty: Float? = 0f,
    
    /**
     * o-series only. Limits reasoning effort. Options: low, medium, high.
     */
    val reasoningEffort: String? = "medium",
    
    /**
     * Specifies the response format.
     */
    val responseFormat: ResponseFormat? = null,
    
    /**
     * Experimental. System will try to produce same result for same seed.
     */
    val seed: Int? = null,
    
    /**
     * Service tier. Options: auto, default, flex.
     */
    val serviceTier: String? = "auto",
    
    /**
     * Up to 4 stop sequences. Generation stops when any is encountered.
     */
    val stop: List<String>? = null,
    
    /**
     * Whether to store this completion for model distillation or evaluation.
     */
    val store: Boolean? = false,
    
    /**
     * Whether to return data as a stream (Server-Sent Events).
     */
    val stream: Boolean? = false,
    
    /**
     * Stream response options, only available when stream: true.
     */
    val streamOptions: StreamOptions? = null,
    
    /**
     * Range: 0~2. Controls randomness; higher values are more random.
     */
    val temperature: Float? = 1f,
    
    /**
     * Controls whether the model calls tools.
     */
    val toolChoice: ToolChoice? = null,
    
    /**
     * List of tools, currently only supports function. Up to 128 functions.
     */
    val tools: List<Tool>? = null,
    
    /**
     * 0~20. For each token, returns the top N most likely tokens and their log probabilities.
     */
    val topLogprobs: Int? = null,
    
    /**
     * Range: 0~1. Nucleus sampling; only considers tokens with cumulative probability mass up to top_p.
     */
    val topP: Float? = 1f,
    
    /**
     * Unique user identifier, useful for abuse detection and tracking.
     */
    val user: String? = null,
    
    /**
     * Web search tool settings, allowing the model to query online information.
     */
    val webSearchOptions: WebSearchOptions? = null
)
```

**Response Types:**
```kotlin
data class ChatResponse(
    val id: String,                       // Unique identifier
    val object: String,                   // "chat.completion" or "chat.completion.chunk"
    val created: Long,                    // Unix timestamp
    val model: String,                    // Model used
    val choices: List<Choice>,            // Completion choices
    val usage: Usage? = null,             // Token usage (non-streaming)
    val systemFingerprint: String? = null,
    val error: ChatError? = null          // Error information if failed
)

data class Choice(
    val index: Int,                       // Choice index
    val message: ChatMessage? = null,     // For non-streaming
    val delta: ChatMessage? = null,       // For streaming
    val finishReason: String? = null      // Why generation stopped
)

data class ChatMessage(
    val role: String,                     // "system", "user", "assistant", "tool"
    val content: String,                  // Message content
    val name: String? = null,             // Author name
    val toolCallId: String? = null,       // Tool call ID (for tool role)
    val toolCalls: List<ToolCall>? = null // Tool calls (for assistant role)
)
```

**Example (Simple using Builder):**
```kotlin
// Using builder function
val request = chatRequest(
    prompt = "Explain quantum computing",
    maxTokens = 500,
    temperature = 0.7f,
    stream = true
)

EdgeAI.chat(request).collect { response ->
    // This matches the actual production usage in ChatViewModel
    val choice = response.choices.firstOrNull()
    
    // For streaming: check if still ongoing (no finishReason)
    if (choice?.finishReason == null) {
        choice?.delta?.content?.let { chunk ->
            if (chunk.isNotBlank()) {
                appendToUI(chunk) // Streaming chunk
            }
        }
    }
    
    // For final response or non-streaming
    choice?.message?.content?.let { finalContent ->
        updateUI(finalContent) // Final content
    }
    
    // Check completion
    if (choice?.finishReason != null) {
        onStreamComplete(choice.finishReason)
    }
}
```

**Example (Full API):**
```kotlin
// Using full ChatRequest model
val messages = listOf(
    ChatMessage(role = "system", content = "You are a helpful assistant."),
    ChatMessage(role = "user", content = "Explain quantum computing")
)

val request = ChatRequest(
    messages = messages,
    model = "gpt-3.5-turbo",
    temperature = 0.7f,
    maxCompletionTokens = 500,
    stream = true
)

EdgeAI.chat(request).collect { response ->
    // Handle response
}
```

---

## Text-to-Speech API

### `EdgeAI.tts(request: TTSRequest): Flow<TTSResponse>`

**Parameters:**
```kotlin
data class TTSRequest(
    /**
     * The text to be converted to speech. Maximum length: 4096 characters.
     */
    val input: String,
    
    /**
     * TTS model name to use for generation
     */
    val model: String,
    
    /**
     * Voice style. Supported values: alloy, ash, ballad, coral, echo, fable, onyx, nova, sage, shimmer, verse.
     */
    val voice: String,
    
    /**
     * Additional instructions to control voice style. 
     * Supported only by gpt-4o-mini-tts; not supported by tts-1/tts-1-hd.
     */
    val instructions: String? = null,
    
    /**
     * Output audio format. Supported values: mp3, opus, aac, flac, wav, pcm, pcm16.
     * Default: mp3
     */
    val responseFormat: String? = "mp3",
    
    /**
     * Playback speed, range: 0.25~4.0, default is 1.0
     */
    val speed: Float? = 1.0f
)
```

**Response Types:**
```kotlin
data class TTSResponse(
    /**
     * Generated audio data as byte array
     */
    val audioData: ByteArray,
    
    /**
     * Audio format (mp3, wav, etc.)
     */
    val format: String = "mp3",
    
    /**
     * Duration in milliseconds (if available)
     */
    val durationMs: Long? = null,
    
    /**
     * Sample rate (if available)
     */
    val sampleRate: Int? = null,
    
    /**
     * Chunk index for streaming audio
     */
    val chunkIndex: Int = 0,
    
    /**
     * Whether this is the last chunk in streaming mode
     */
    val isLastChunk: Boolean = true,
    
    /**
     * Number of audio channels
     */
    val channels: Int = 1,
    
    /**
     * Audio bit depth
     */
    val bitDepth: Int = 16
)
```

**Example:**
```kotlin
val request = ttsRequest(
    input = "Hello, this is a test message",
    voice = "alloy",
    speed = 1.0f
)

EdgeAI.tts(request).collect { response ->
    playAudio(response.audioData)
}
```

---

## Speech-to-Text API

### `EdgeAI.asr(request: ASRRequest): Flow<ASRResponse>`

**Parameters:**
```kotlin
data class ASRRequest(
    /**
     * Audio file data as byte array
     */
    val file: ByteArray,
    
    /**
     * ASR model name to use (e.g., "whisper-1")
     */
    val model: String,
    
    /**
     * Language code for the audio (e.g., "en", "zh"). If null, language will be auto-detected.
     */
    val language: String? = null,
    
    /**
     * Optional prompt to guide the transcription style
     */
    val prompt: String? = null,
    
    /**
     * Response format. Supported values: json, text, srt, verbose_json, vtt
     */
    val responseFormat: String? = "json",
    
    /**
     * Additional data to include in response
     */
    val include: List<String>? = null,
    
    /**
     * Whether to enable streaming transcription
     */
    val stream: Boolean? = false,
    
    /**
     * Temperature for sampling (0.0-1.0). Higher values increase randomness.
     */
    val temperature: Float? = 0f,
    
    /**
     * Timestamp granularities to include. Options: "word", "segment"
     * Note: "word" requires responseFormat="verbose_json"
     */
    val timestampGranularities: List<String>? = listOf("segment")
)
```

**Response Types:**
```kotlin
data class ASRResponse(
    val text: String,                    // Transcribed text
    val segments: List<TranscriptionSegment>? = null, // Detailed segments (verbose_json)
    val language: String? = null,       // Detected language
    val rawResponse: String? = null,    // Raw response in requested format
    val isChunk: Boolean = false        // Whether this is streaming chunk
)

data class TranscriptionSegment(
    val id: Int,                        // Segment ID
    val seek: Int,                      // Seek position
    val start: Float,                   // Start time in seconds
    val end: Float,                     // End time in seconds
    val text: String,                   // Segment text
    val tokens: List<Int>? = null,      // Token IDs
    val temperature: Float? = null,     // Temperature used
    val avgLogprob: Float? = null,      // Average log probability
    val compressionRatio: Float? = null, // Compression ratio
    val noSpeechProb: Float? = null,    // No speech probability
    val words: List<WordTimestamp>? = null // Word-level timestamps
)

data class WordTimestamp(
    val word: String,                   // The word
    val start: Float,                   // Start time in seconds
    val end: Float                      // End time in seconds
)
```

**Example:**
```kotlin
val request = asrRequest(
    audioBytes = audioBytes,
    model = "whisper-1",
    language = "en"
)

EdgeAI.asr(request).collect { response ->
    updateUI(response.text)
}

// With detailed timestamps
val detailedRequest = asrRequestDetailed(
    audioBytes = audioBytes,
    model = "whisper-1",
    includeWordTimestamps = true
)

EdgeAI.asr(detailedRequest).collect { response ->
    response.segments?.forEach { segment ->
        println("${segment.start}-${segment.end}: ${segment.text}")
    }
}
```

---

## Initialization API

### `EdgeAI.initializeAndWait(context: Context, timeoutMs: Long = 10000): Unit`

**Parameters:**
- `context`: Android Context
- `timeoutMs`: Connection timeout in milliseconds

**Throws:**
- `ServiceConnectionException`: When BreezeApp Engine is not available

**Example:**
```kotlin
try {
    EdgeAI.initializeAndWait(context, timeoutMs = 10000)
    Log.i("EdgeAI", "Initialized successfully")
} catch (e: ServiceConnectionException) {
    Log.e("EdgeAI", "Initialization failed", e)
}
```

### `EdgeAI.shutdown(): Unit`

**Example:**
```kotlin
// Call when app exits
EdgeAI.shutdown()
```

---

## Configuration API

### `EdgeAI.setLogLevel(level: LogLevel): Unit`

**LogLevel Options:**
- `LogLevel.DEBUG`: Detailed logging
- `LogLevel.INFO`: Information logging
- `LogLevel.WARN`: Warning logging
- `LogLevel.ERROR`: Error logging only

**Example:**
```kotlin
// Enable debug logging (development)
EdgeAI.setLogLevel(LogLevel.DEBUG)

// Disable logging (production)
EdgeAI.setLogLevel(LogLevel.ERROR)
```

---

## Supporting Data Classes

The following data classes support the main request/response models:

```kotlin
/**
 * Supporting data classes for ChatRequest parameters
 */
@Parcelize
data class AudioParams(
    val voice: String,
    val format: String? = "wav"
) : Parcelable

@Parcelize
data class PredictionParams(
    val type: String,
    val content: String
) : Parcelable

@Parcelize
data class ResponseFormat(
    val type: String,
    val jsonSchema: JsonSchema? = null
) : Parcelable

@Parcelize
data class JsonSchema(
    val name: String,
    val description: String? = null,
    val schema: Map<String, Any>
) : Parcelable

@Parcelize
data class StreamOptions(
    val includeUsage: Boolean? = false
) : Parcelable

@Parcelize
data class ToolChoice(
    val type: String,
    val function: FunctionChoice? = null
) : Parcelable

@Parcelize
data class Tool(
    val type: String,
    val function: Function
) : Parcelable

@Parcelize
data class Function(
    val name: String,
    val description: String? = null,
    val parameters: Map<String, Any>? = null
) : Parcelable

@Parcelize
data class FunctionChoice(
    val name: String
) : Parcelable

@Parcelize
data class ToolCall(
    val id: String,
    val type: String,
    val function: FunctionCall
) : Parcelable

@Parcelize
data class FunctionCall(
    val name: String,
    val arguments: String
) : Parcelable

@Parcelize
data class WebSearchOptions(
    val enabled: Boolean = true,
    val maxResults: Int? = 10
) : Parcelable

@Parcelize
data class LogProbs(
    val tokens: List<String>,
    val tokenLogprobs: List<Float>,
    val topLogprobs: List<Map<String, Float>>? = null
) : Parcelable

@Parcelize
data class CompletionTokensDetails(
    val reasoningTokens: Int? = null
) : Parcelable
```

---

## Builder Functions

EdgeAI provides convenient builder functions to simplify common use cases:

```kotlin
/**
 * Simple chat completion builder for basic text conversations
 */
fun chatRequest(
    model: String? = null, // Let engine decide based on configuration
    prompt: String,
    systemPrompt: String? = null,
    temperature: Float? = null,
    maxTokens: Int? = null,
    stream: Boolean = false
): ChatRequest

/**
 * Chat completion builder with conversation history
 */
fun chatRequestWithHistory(
    model: String? = null, // Let engine decide based on configuration  
    messages: List<ChatMessage>,
    temperature: Float? = null,
    maxTokens: Int? = null,
    stream: Boolean = false
): ChatRequest

/**
 * Simple TTS request builder
 */
fun ttsRequest(
    input: String,
    model: String = "tts-1",
    voice: String = "alloy",
    speed: Float? = null,
    format: String = "pcm"
): TTSRequest

/**
 * Simple ASR request builder
 */
fun asrRequest(
    audioBytes: ByteArray,
    model: String = "whisper-1",
    language: String? = null,
    format: String = "json",
    temperature: Float? = null,
    stream: Boolean = false
): ASRRequest

/**
 * ASR request builder with detailed options
 */
fun asrRequestDetailed(
    audioBytes: ByteArray,
    model: String = "whisper-1",
    language: String? = null,
    prompt: String? = null,
    format: String = "verbose_json",
    includeWordTimestamps: Boolean = false,
    temperature: Float? = null,
    stream: Boolean = false
): ASRRequest
```

---

## Exception Types

```kotlin
sealed class EdgeAIException : Exception() {
    class ServiceConnectionException(message: String) : EdgeAIException()
    class InvalidRequestException(message: String) : EdgeAIException()
    class TimeoutException(message: String) : EdgeAIException()
    class NetworkException(message: String) : EdgeAIException()
    class AuthenticationException(message: String) : EdgeAIException()
    class UnknownException(message: String) : EdgeAIException()
}
```

---

## Error Handling

Chat responses include structured error information:

```kotlin
data class ChatError(
    val code: String,                    // Error code (e.g., "G100" for Guardian violations)
    val message: String,                 // Human-readable message
    val type: String,                    // Error type category
    val metadata: Map<String, Any>? = null, // Additional context
    val guardianInfo: GuardianErrorInfo? = null // Guardian-specific details
)

data class GuardianErrorInfo(
    val stage: String,                   // "input" or "output"
    val safetyStatus: String,           // Safety status
    val riskScore: Double,              // Risk score (0.0-1.0)
    val riskCategories: List<String>,   // Detected risk categories
    val suggestion: String? = null,     // User-friendly suggestion
    val confidence: Double = 0.0        // Confidence score
)
```