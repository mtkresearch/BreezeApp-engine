package com.mtkresearch.breezeapp.edgeai

import android.os.Parcelable
import kotlinx.parcelize.Parcelize
import kotlinx.parcelize.RawValue

/**
 * Request for standard chat completions
 * Based on industry-standard API specifications
 */
@Parcelize
data class ChatRequest(
    /**
     * Array of chat messages. Each message must include a role and content.
     */
    val messages: List<ChatMessage>,
    
    /**
     * The model ID to use for generating responses
     */
    val model: String,
    
    /**
     * Audio output parameters. Required when requesting audio output.
     */
    val audio: AudioParams? = null,
    
    /**
     * Range: -2.0 ~ 2.0. Positive values penalize tokens that appear frequently.
     */
    val frequencyPenalty: Float? = 0f,
    
    /**
     * Adjusts the probability of specific tokens. Format: token ID mapped to bias value (-100~100).
     */
    val logitBias: @RawValue Map<String, Float>? = null,
    
    /**
     * Whether to return log probabilities of output tokens.
     */
    val logprobs: Boolean? = false,
    
    /**
     * Limits the maximum number of tokens generated by the model.
     */
    val maxCompletionTokens: Int? = null,
    
    /**
     * Up to 16 key-value pairs for custom structured information.
     */
    val metadata: @RawValue Map<String, String>? = null,
    
    /**
     * Specifies the desired output modalities. Default is ["text"].
     */
    val modalities: List<String>? = listOf("text"),
    
    /**
     * Number of response options to generate for each input message.
     */
    val n: Int? = 1,
    
    /**
     * Whether to enable parallel tool (function) calls.
     */
    val parallelToolCalls: Boolean? = true,
    
    /**
     * Prediction output settings for faster responses.
     */
    val prediction: PredictionParams? = null,
    
    /**
     * Range: -2.0 ~ 2.0. Positive values encourage new topics.
     */
    val presencePenalty: Float? = 0f,
    
    /**
     * o-series only. Limits reasoning effort. Options: low, medium, high.
     */
    val reasoningEffort: String? = "medium",
    
    /**
     * Specifies the response format.
     */
    val responseFormat: ResponseFormat? = null,
    
    /**
     * Experimental. System will try to produce same result for same seed.
     */
    val seed: Int? = null,
    
    /**
     * Service tier. Options: auto, default, flex.
     */
    val serviceTier: String? = "auto",
    
    /**
     * Up to 4 stop sequences. Generation stops when any is encountered.
     */
    val stop: List<String>? = null,
    
    /**
     * Whether to store this completion for model distillation or evaluation.
     */
    val store: Boolean? = false,
    
    /**
     * Whether to return data as a stream (Server-Sent Events).
     */
    val stream: Boolean? = false,
    
    /**
     * Stream response options, only available when stream: true.
     */
    val streamOptions: StreamOptions? = null,
    
    /**
     * Range: 0~2. Controls randomness; higher values are more random.
     */
    val temperature: Float? = 1f,
    
    /**
     * Controls whether the model calls tools.
     */
    val toolChoice: ToolChoice? = null,
    
    /**
     * List of tools, currently only supports function. Up to 128 functions.
     */
    val tools: List<Tool>? = null,
    
    /**
     * 0~20. For each token, returns the top N most likely tokens and their log probabilities.
     */
    val topLogprobs: Int? = null,
    
    /**
     * Range: 0~1. Nucleus sampling; only considers tokens with cumulative probability mass up to top_p.
     */
    val topP: Float? = 1f,
    
    /**
     * Unique user identifier, useful for abuse detection and tracking.
     */
    val user: String? = null,
    
    /**
     * Web search tool settings, allowing the model to query online information.
     */
    val webSearchOptions: WebSearchOptions? = null
) : Parcelable

/**
 * Chat message with role and content
 */
@Parcelize
data class ChatMessage(
    /**
     * The role of the message author. One of: system, user, assistant, tool
     */
    val role: String,
    
    /**
     * The content of the message. Can be text or multimodal content.
     */
    val content: String,
    
    /**
     * Optional name of the author of this message
     */
    val name: String? = null,
    
    /**
     * Tool call ID this message is responding to (for tool role)
     */
    val toolCallId: String? = null,
    
    /**
     * Tool calls generated by the model (for assistant role)
     */
    val toolCalls: List<ToolCall>? = null
) : Parcelable

/**
 * Response from standard chat completions
 */
@Parcelize
data class ChatResponse(
    /**
     * Unique identifier for the chat completion
     */
    val id: String,
    
    /**
     * Object type, always "chat.completion" or "chat.completion.chunk"
     */
    val `object`: String,
    
    /**
     * Unix timestamp of when the completion was created
     */
    val created: Long,
    
    /**
     * Model used for the completion
     */
    val model: String,
    
    /**
     * List of completion choices
     */
    val choices: List<Choice>,
    
    /**
     * Token usage statistics (only in non-streaming mode)
     */
    val usage: Usage? = null,
    
    /**
     * System fingerprint
     */
    val systemFingerprint: String? = null
) : Parcelable

/**
 * A completion choice
 */
@Parcelize
data class Choice(
    /**
     * Index of this choice
     */
    val index: Int,
    
    /**
     * The message generated by the model (for non-streaming)
     */
    val message: ChatMessage? = null,
    
    /**
     * The delta containing new content (for streaming)
     */
    val delta: ChatMessage? = null,
    
    /**
     * Log probability information for the choice
     */
    val logprobs: LogProbs? = null,
    
    /**
     * Reason the model stopped generating tokens
     */
    val finishReason: String? = null
) : Parcelable

/**
 * Token usage statistics
 */
@Parcelize
data class Usage(
    /**
     * Number of tokens in the prompt
     */
    val promptTokens: Int,
    
    /**
     * Number of tokens in the completion
     */
    val completionTokens: Int,
    
    /**
     * Total number of tokens used
     */
    val totalTokens: Int,
    
    /**
     * Breakdown of completion tokens
     */
    val completionTokensDetails: CompletionTokensDetails? = null
) : Parcelable

/**
 * Supporting data classes for optional parameters
 */
@Parcelize
data class AudioParams(
    val voice: String,
    val format: String? = "wav"
) : Parcelable

@Parcelize
data class PredictionParams(
    val type: String,
    val content: String
) : Parcelable

@Parcelize
data class ResponseFormat(
    val type: String,
    val jsonSchema: JsonSchema? = null
) : Parcelable

@Parcelize
data class JsonSchema(
    val name: String,
    val description: String? = null,
    val schema: @RawValue Map<String, Any>
) : Parcelable

@Parcelize
data class StreamOptions(
    val includeUsage: Boolean? = false
) : Parcelable

@Parcelize
data class ToolChoice(
    val type: String,
    val function: FunctionChoice? = null
) : Parcelable

@Parcelize
data class Tool(
    val type: String,
    val function: Function
) : Parcelable

@Parcelize
data class Function(
    val name: String,
    val description: String? = null,
    val parameters: @RawValue Map<String, Any>? = null
) : Parcelable

@Parcelize
data class FunctionChoice(
    val name: String
) : Parcelable

@Parcelize
data class ToolCall(
    val id: String,
    val type: String,
    val function: FunctionCall
) : Parcelable

@Parcelize
data class FunctionCall(
    val name: String,
    val arguments: String
) : Parcelable

@Parcelize
data class WebSearchOptions(
    val enabled: Boolean = true,
    val maxResults: Int? = 10
) : Parcelable

@Parcelize
data class LogProbs(
    val tokens: List<String>,
    val tokenLogprobs: List<Float>,
    val topLogprobs: @RawValue List<Map<String, Float>>? = null
) : Parcelable

@Parcelize
data class CompletionTokensDetails(
    val reasoningTokens: Int? = null
) : Parcelable 